{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "069498c9",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------\n",
    "# ðŸš¨ MASTER SETUP BLOCK - DO NOT EDIT THIS CELL\n",
    "# ---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88be342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# ðŸš€ MASTER DATA PIPELINE (LOAD -> CLEAN -> FILL)\n",
    "# ==============================================================================\n",
    "# Instructions:\n",
    "# 1. Place 'US_Accidents_March23.csv' in a folder named 'data'.\n",
    "# 2. Run the cells below in order to get a clean dataframe ready for analysis.\n",
    "# ==============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea48a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 1. LOAD DATA\n",
    "# ---------------------------------------------------------\n",
    "file_path = os.path.join('data', 'US_Accidents_March23.csv')\n",
    "print(\"â³ Loading dataset (Sample Mode)...\")\n",
    "# âš ï¸ SAFETY: Loading 500k rows for development.\n",
    "# To run on the FULL dataset for the final report, remove 'nrows=500000'\n",
    "df = pd.read_csv(file_path, nrows=500000)\n",
    "print(f\"âœ… Loaded {df.shape[0]} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ddc7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 2. DROP USELESS COLUMNS\n",
    "# ---------------------------------------------------------\n",
    "# We keep 'Amenity' as requested, but drop other noise.\n",
    "cols_to_delete = [\n",
    "    # Metadata & IDs\n",
    "    'ID', 'Source', 'Country', 'Zipcode', 'Timezone', 'Airport_Code', 'Description',\n",
    "\n",
    "    # Redundant Time/Weather\n",
    "    'Weather_Timestamp', 'Wind_Chill(F)', 'Wind_Direction', 'Pressure(in)', 'Precipitation(in)',\n",
    "    'Civil_Twilight', 'Nautical_Twilight', 'Astronomical_Twilight',\n",
    "\n",
    "    # Too Granular or Mostly False\n",
    "    'Street', 'Turning_Loop',\n",
    "\n",
    "    # High Missing Values\n",
    "    'End_Lat', 'End_Lng'\n",
    "]\n",
    "df.drop(columns=cols_to_delete, errors='ignore', inplace=True)\n",
    "print(f\"ðŸ—‘ï¸ Dropped {len(cols_to_delete)} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f36a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 3. RENAME COLUMNS (For easier coding)\n",
    "# ---------------------------------------------------------\n",
    "df.rename(columns={\n",
    "    'Distance(mi)': 'Distance',\n",
    "    'Temperature(F)': 'Temp',\n",
    "    'Humidity(%)': 'Humidity',\n",
    "    'Visibility(mi)': 'Visibility',\n",
    "    'Wind_Speed(mph)': 'Wind_Speed',\n",
    "    'Weather_Condition': 'Weather'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1bd645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 4. FIX DATE & TIME\n",
    "# ---------------------------------------------------------\n",
    "print(\"ðŸ•’ Converting timestamps and calculating duration...\")\n",
    "df['Start_Time'] = pd.to_datetime(df['Start_Time'], errors='coerce')\n",
    "df['End_Time'] = pd.to_datetime(df['End_Time'], errors='coerce')\n",
    "\n",
    "# Drop rows where Start_Time or End_Time is unknown (cannot analyze without time)\n",
    "df.dropna(subset=['Start_Time', 'End_Time'], inplace=True)\n",
    "\n",
    "# Create \"Duration\" (in Minutes)\n",
    "df['Duration'] = (df['End_Time'] - df['Start_Time']).dt.total_seconds() / 60\n",
    "\n",
    "# Filter logic: Remove negative durations or accidents lasting > 1 week (bad data)\n",
    "df = df[(df['Duration'] > 0) & (df['Duration'] < 10080)]\n",
    "\n",
    "# Extract Temporal Features\n",
    "df['Year'] = df['Start_Time'].dt.year\n",
    "df['Month'] = df['Start_Time'].dt.month\n",
    "df['Hour'] = df['Start_Time'].dt.hour\n",
    "df['Weekday'] = df['Start_Time'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28cc55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 5. FIX MISSING VALUES (IMPUTATION)\n",
    "# ---------------------------------------------------------\n",
    "print(\"ðŸ”§ Filling empty values...\")\n",
    "# A. Numerical Columns -> Fill with MEDIAN\n",
    "weather_nums = ['Temp', 'Humidity', 'Visibility', 'Wind_Speed']\n",
    "for col in weather_nums:\n",
    "    if col in df.columns:\n",
    "        median_val = df[col].median()\n",
    "        df[col] = df[col].fillna(median_val)\n",
    "\n",
    "# B. Categorical Columns -> Fill with MODE (Most Frequent)\n",
    "categorical_cols = ['Weather', 'Sunrise_Sunset', 'City']\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        if not df[col].mode().empty:\n",
    "            mode_val = df[col].mode()[0]\n",
    "            df[col] = df[col].fillna(mode_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938031ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 6. FINAL STATUS CHECK\n",
    "# ---------------------------------------------------------\n",
    "print(\"\\nâœ… DATA PIPELINE COMPLETE!\")\n",
    "print(f\"Final Shape: {df.shape}\")\n",
    "print(f\"Any missing values left? {df.isna().sum().sum()}\")\n",
    "print(\"------------------------------------------------\")\n",
    "print(\"Columns ready for analysis:\", list(df.columns))\n",
    "df.head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
